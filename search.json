[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "alto2dataset",
    "section": "",
    "text": "#TODO"
  },
  {
    "objectID": "europena.html",
    "href": "europena.html",
    "title": "Europeana newspaper parsers",
    "section": "",
    "text": "The goal of this code is to create a pipeline for parsing the Europeana newspaper bulk downloads and converting the orignal ALTO XML formats + metadata into a format that can be ingested easily into the ðŸ¤— datasets library and cons\nfor #BigLAM. This code is mostly colated from other places. We used nbdev to give our code some:\nnote some of these parsers are likely to be more generic but weâ€™ll develop them for europena newspapers for now. Once they have been tested on other collections they may be moved to a core module."
  },
  {
    "objectID": "europena.html#alto-processing",
    "href": "europena.html#alto-processing",
    "title": "Europeana newspaper parsers",
    "section": "ALTO Processing",
    "text": "ALTO Processing\nALTO is an XML format commonly used to store the outout of Opitcal Character Recogniton software.\n\nCreate test data\nA small amount of test data is included in the repository and versioned with Git. To avoid bloating the repository too much the below cell can either be run as part of test (including) slow tests or run locally to give oneself a bigger amount of data to test methods with.\n\n# # |slow\n# !mkdir test_data\n# !aria2c -x 4 -d test_data/ ftp://download.europeana.eu/newspapers/fulltext/alto/9200396.zip\n# !unzip test_data/*.zip -d test_data/\n# !rm test_data/*.zip\n# !mkdir test_data/metadata\n# !aria2c -x 4 -d test_data/metadata/ ftp://download.europeana.eu/newspapers/metadata/9200396.zip\n# !unzip test_data/metadata/*.zip -d test_data/metadata/\n# !rm test_data/metadata/*.zip\n\n\nalto_xmls = [f for f in Path(\"test_data\").rglob(\"*.xml\") if \"edm\" not in f.name]\nlen(alto_xmls)\n\n106562"
  },
  {
    "objectID": "europena.html#parse-alto-xmls",
    "href": "europena.html#parse-alto-xmls",
    "title": "Europeana newspaper parsers",
    "section": "Parse ALTO XMLs",
    "text": "Parse ALTO XMLs\nThe first step is to parse the xml file from disk into a elementree that we can use for other takss stolen from; https://github.com/cneud/alto-tools/blob/master/alto_tools.py\n\n\nalto_parse\n\n alto_parse (alto:Union[str,pathlib.Path], **kwargs)\n\nConvert ALTO xml file to element tree\n\nalto_xmls[0]\n\nPath('test_data/9200396/BibliographicResource_3000118436002/88.xml')\n\n\n\nfname, xml, ns = alto_parse(alto_xmls[0])\n\n\nassert all([fname, xml, ns])\nPath(\"fake.xml\").touch(exist_ok=True)\nbad_xml = alto_parse(Path(\"fake.xml\"))\n# assert isinstance(bad_xml, None)\n\n2022-08-18 12:11:06.762 | ERROR    | __main__:alto_parse:7 - Parser Error in file 'fake.xml': no element found: line 1, column 0\n\n\n\n\n\nget_alto_text\n\n get_alto_text (xml, xmlns, join_lines=True)\n\nExtract text content from ALTO xml file\n\ntext, wc, std_ocr = get_alto_text(xml, ns)\nassert all([text, wc, std_ocr])\nassert isinstance(text, str)\nassert isinstance(wc, float)\nassert isinstance(std_ocr, float)\n\n\n\n\nalto_illustrations\n\n alto_illustrations (xml, xmlns)\n\nExtract bounding boxes of illustration from ALTO xml file\n\nalto_illustrations(xml, ns)\n\n[]\n\n\n\ndef get_illustrations(xmls):\n    for file in xmls:\n        with open(file, \"r\") as f:\n            for line in f:\n                if \"Illustration\" in line:\n                    yield file\n                    break\n\n\nfrom toolz import take\n\n\nillustration_xmls = list(take(10, get_illustrations(alto_xmls)))\n\n\nillustration_xmls\n\n[Path('test_data/9200396/BibliographicResource_3000118436002/1.xml'),\n Path('test_data/9200396/BibliographicResource_3000118435687/76.xml'),\n Path('test_data/9200396/BibliographicResource_3000118435687/3.xml'),\n Path('test_data/9200396/BibliographicResource_3000118435687/1.xml'),\n Path('test_data/9200396/BibliographicResource_3000118436230/76.xml'),\n Path('test_data/9200396/BibliographicResource_3000118436230/9.xml'),\n Path('test_data/9200396/BibliographicResource_3000118436230/20.xml'),\n Path('test_data/9200396/BibliographicResource_3000118436230/33.xml'),\n Path('test_data/9200396/BibliographicResource_3000118436230/32.xml'),\n Path('test_data/9200396/BibliographicResource_3000118436230/1.xml')]\n\n\n\nfor file in illustration_xmls:\n    fname, xml, ns = alto_parse(file)\n    bounding_boxes = alto_illustrations(xml, ns)\n    assert bounding_boxes\n    for box in bounding_boxes:\n        assert isinstance(box, list)\n        assert len(box) == 4\n        assert all(isinstance(x, float) for x in box)"
  },
  {
    "objectID": "europena.html#newspaper-page-container",
    "href": "europena.html#newspaper-page-container",
    "title": "Europeana newspaper parsers",
    "section": "Newspaper page container",
    "text": "Newspaper page container\n\n\nNewspaperPageAlto\n\n NewspaperPageAlto (fname:Union[str,pathlib.Path], text:Optional[str],\n                    mean_ocr:Optional[float], std_ocr:Optional[float],\n                    bounding_boxes:List[Optional[float]])\n\nMethod generated by attrs for class NewspaperPageAlto.\n\n\n\nparse_newspaper_page\n\n parse_newspaper_page (xml_fname:Union[str,pathlib.Path])\n\n\npage = parse_newspaper_page(alto_xmls[20])\n\n\nassert page\nassert isinstance(page, NewspaperPageAlto)\nassert isinstance(page.text, (str, None))\nassert isinstance(page.mean_ocr, (float, None))\nassert isinstance(page.std_ocr, (float, None))\nassert isinstance(page.bounding_boxes, List)\nassert isinstance(page.item_id, str)\n\n\npage\n\nNewspaperPageAlto(fname=Path('test_data/9200396/BibliographicResource_3000118436002/9.xml'), text=\"Ã¯g. HÃ©ctmlre . SSS du thrÃ´ne & de lÃ©giflation dans le roÃ¯aume, lâ€™extinÃ¢ion des guerres entre le Souverain & les vaffaux , entre les provinces & les provinces provinces ; quâ€™ainfi fans entrer dans les motifs Ã  ne juger que par lâ€™Ã©vÃ©nementles croifa- des ont Ã©pargnÃ© Ã  la nation plus de fang quâ€™elles nâ€™en ont fait rÃ©pandre, quâ€™elles ont pofÃ© la bafe & les fondemens de la tranquillitÃ© tranquillitÃ© intÃ©rieure de lâ€™Ã©tat. Je ne vous ferai pas remarquer que lâ€™entreprife de Louis nâ€™offroit point dâ€™obftacles capables de ralentir fort ^ .courage & dâ€™alarmer fa fagefl'e; quâ€™on a voit vÃ» Godefroy de Bouillon , avec les dÃ©bris dâ€™une armÃ©e, amas fortuit de diverfes nations, nations, Ã©lever dans JÃ©rufalem un thrÃ´ne qui, vainqueur des Mufulmans , nâ€™a pÃ©ri que par Autres les di vidons & les perfidies des chrÃ©tiens, je rÃ©fl. fur les nâ€™ajouterai point que Chypre, Conftantino- croifadesii pie, fournis Ã  des princes de la communion A Q Q a lÃ‚oÃ»ÃŠ latine, donnoit Ã  Louis des facilitÃ©s que nâ€™eut , 77 g, p .. point Godefroid de Bouillon â€ž. â€” 15. DÃ©c, Le parallÃ¨le de Bajazet & de St, Louis, P- quâ€™on lit dans le panÃ©gyrique de ce Saint, eft un tableau dont tous les traits concou rent au triomphe de la religion du faint Roi. Les . panÃ©gyriftes des hÃ©ros turcs & Chinois, ( & i! y en a aujourdâ€™hui un bien grand nombre ) font priÃ©s dâ€™en faire un qui puiffe lÃ©rvir de pendant Ã  celui-ci. â€œ Que le fe&ateur de Mahomet dÃ©ploie maintenant fes faites, il nous montrera lâ€™Aile , lâ€™Afrique, lâ€™Afrique, lâ€™Europe englouties par fes conquÃ©rons , & le thrÃ´ne de fes Califes Ã©levÃ© fur les ruines fie lâ€™apivers j il nous piontrera donc ce courage courage\", mean_ocr=0.5861000468510345, std_ocr=0.1977007715324908, bounding_boxes=[], item_id='9200396/BibliographicResource_3000118436002')"
  },
  {
    "objectID": "europena.html#get-metadata",
    "href": "europena.html#get-metadata",
    "title": "Europeana newspaper parsers",
    "section": "Get metadata",
    "text": "Get metadata\nThe next step is to create some functionality to get metadata for the items. There are two possible ways we can do this: - via the metadata download dumps - via the Europena API\n\nmetadata_examples = list(take(500, Path(\"test_data\").rglob(\"*edm.xml\")))\n\n\nfrom datetime import datetime\n\n\n\nNewspaperPageMetadata\n\n NewspaperPageMetadata (metadata_xml_fname:Union[str,pathlib.Path],\n                        title:Optional[str], issued:Optional[str],\n                        language:Union[List[str],str,NoneType],\n                        item_iiif_url:Optional[str],\n                        all_metadata_dict:Dict[Any,Any])\n\nMethod generated by attrs for class NewspaperPageMetadata.\n\n\n\nget_metadata_from_xml\n\n get_metadata_from_xml (xml_file:Union[pathlib.Path,str])\n\n\nxml_file = metadata_examples[-23]\nwith open(xml_file, \"r\") as f:\n    xml = xmltodict.parse(f.read())\n\n\nfor metadata_xml in metadata_examples:\n    metadata = get_metadata_from_xml(metadata_xml)\n    assert metadata\n    assert isinstance(metadata.language, (list, None))"
  },
  {
    "objectID": "europena.html#linking-metadata-and-xml",
    "href": "europena.html#linking-metadata-and-xml",
    "title": "Europeana newspaper parsers",
    "section": "Linking metadata and XML",
    "text": "Linking metadata and XML\nWe need to be able to link from the data we got from the ALTO XML with our metadata and smush them together. We have our page.item_id attribute which will hopefully be sufficient to grab the related metadata file.\n\nmetadata.issued_parsed\n\ndatetime.datetime(1783, 6, 1, 0, 0)\n\n\n\n\nget_metadata_for_page\n\n get_metadata_for_page (page:__main__.NewspaperPageAlto,\n                        metadata_directory:Optional[str]=None)\n\n\nmetadata = get_metadata_for_page(page, metadata_directory=\"test_data/metadata\")\nassert metadata\nassert isinstance(metadata, NewspaperPageMetadata)\nassert page.item_id.split(\"_\")[-1] in metadata.metadata_xml_fname"
  },
  {
    "objectID": "europena.html#issue-processor",
    "href": "europena.html#issue-processor",
    "title": "Europeana newspaper parsers",
    "section": "Issue processor",
    "text": "Issue processor\n\n\nNewspaperPage\n\n NewspaperPage (fname:Union[str,pathlib.Path], text:Optional[str],\n                mean_ocr:Optional[float], std_ocr:Optional[float],\n                bounding_boxes:List[Optional[float]], item_id:str,\n                metadata_xml_fname:Union[str,pathlib.Path],\n                title:Optional[str], issued:Optional[str],\n                issued_parsed:Optional[datetime.datetime],\n                language:Optional[List[str]], item_iiif_url:Optional[str])\n\nMethod generated by attrs for class NewspaperPage.\n\n\n\nprocess_newspaper_page\n\n process_newspaper_page (xml_file:Union[str,pathlib.Path],\n                         metadata_directory:Optional[str]=None)\n\n\nassert all(\n    process_newspaper_page(xml, metadata_directory=\"test_data/metadata\")\n    for xml in alto_xmls[:32]\n)\n\n\nprocess_newspaper_page(alto_xmls[0], metadata_directory=\"test_data/metadata\")\n\nNewspaperPage(fname='test_data/9200396/BibliographicResource_3000118436002/88.xml', text='Idem , par Mr***. en lui prifentent un exemplaire de fes fermons imprimÃ©s. 15. DÃ©cembre. DÃ©cembre. Voix {_ la), du vi ni patriote catholique, oppofÃ©e Ã  celle des faux patriotes toltrans. 1. Septembre. 1 1 â– ladre parmi les Ombres, avec cette Ã©pigraphe: etgo erruvtmus & errare fecimus. 1. Novembre. . . 332 Voltaire de retour des Ombres , & fur le point dâ€™y retourner pour nâ€™en plus revenir l. Novembre. Page 57o 333 â€™On fait favoir que les biens des ci devant JÃ©fuites de la niÃ©taiÃ®ie Ã  Kockellchcur Ã  Â«ne lieue de cette ville, confftans ea maifocs, terres, prairies , Ã©tangs & bois , partagÃ©s en dix-neuf lots , font Ã  vendre , chaque lot fÃ©parÃ©- ment ; que les amateurs dâ€™un ou plulÃ®eurs lots pourront sâ€™adrefler au Receveur des Domaines Luxembourg Leonardy pendant le mois de Janvier prochain , & faire leurs offres , aprÃ¨s lequel mois Ã©coulÃ© lâ€™on ne recevera plus aucune offie i & que le 19e. de ce mois de DÃ©cembre, a s heures du matin & jours fuivans, le dit Receveur vendra au dit Kockclfcheur tous les dirvaux foin, paille, &. les meubles de ladite mÃ©tairie .au plus offrant & dernier enchÃ©rilleur, argent comptant. Luxembourg le ; DÃ©cembre 1773. CD bÃªtes Ã  cornes & autres beftianx >', mean_ocr=0.44245891427834905, std_ocr=0.18921927369326655, bounding_boxes=[], item_id='9200396/BibliographicResource_3000118436002', metadata_xml_fname='test_data/metadata/http%3A%2F%2Fdata.theeuropeanlibrary.org%2FBibliographicResource%2F3000118436002.edm.xml', title='Journal historique et littÃ©raire', issued='1776-12-15', issued_parsed=datetime.datetime(1776, 12, 15, 0, 0), language=['fr'], item_iiif_url='https://iiif.europeana.eu/image/2TS6TSUK5ULAT2TQMYN7UGBDCPKQBLHQPTPDD6GGYB4QOZXR72EQ/presentation_images/bc994340-0232-11e6-a696-fa163e2dd531/node-3/image/BNL/Journal_historique_et_littÃ©raire/1776/12/15/00547/full/full/0/default.jpg', multi_language=False)"
  },
  {
    "objectID": "europena.html#load-into-datasets",
    "href": "europena.html#load-into-datasets",
    "title": "Europeana newspaper parsers",
    "section": "Load into datasets",
    "text": "Load into datasets\n\npage = process_newspaper_page(alto_xmls[200], metadata_directory=\"test_data/metadata\")\npage\n\nNewspaperPage(fname='test_data/9200396/BibliographicResource_3000118436230/38.xml', text=\"Journal hÃ®fl. & litt . licjri , rÃ©gent de Lithuanie, â€”â€” regimens dâ€™infanterie, qui font au nombre de 38 , doivent Ãªtre portÃ©s Ã  j 500 hommes, hommes, au lieu de 1200, dont ils Ã©toient Compofcs ci'- devant ; lÃ©s pontonniers qui Ã©toient de 608 hommes, en formeront 1000, ainfi que le corps dâ€™artillerie ; pour cÃ§ dernier on nâ€™admet que des gens inftruits & qui ont achevÃ© leurs Ã©tudes. La cavalerie- nationale sâ€™accroÃ®t de jour en jour. Chaque rÃ©giment dâ€™Oulans fera augmentÃ© de 290 hommes. hommes. 'On entend par-tout les tambours annoncer annoncer la recrue, depuis environ 4 femaines, il nous eft arrive au-delÃ  de 5000 des plus beaux hommes, la plupart dÃ©ferteurs allemands. Jufquâ€™ici nous' ignorons abfolument lâ€™objet dâ€™une levÃ©e fi nombrenfe & fi. extraordinaire. Dantzig (/e 3 Janvier. ) Lâ€™aflÃ¨mblÃ©e des trois Ordres de la ville , convoquÃ©e le c8 DÃ©cembre, en confÃ©quence des ordres venus de Varfovie pour figner la convention relative relative Ã  la navigation de la Viftule, fut prorogÃ©e prorogÃ©e au lendemain ; & câ€™eft ce jour-lÃ  que les trois Ordres ont donnÃ© leur confentement unanime pour la fignature de cette convention. convention. Le magiftrat a fait informer de cette, rÃ©folution M r . de Pfennig, commiffaire de Pologne, M r . de PÃ©terfon , rÃ©fident de Ruf- fie, & M r . de Lindenowski, rÃ©fident de Pruffe, avec priere dâ€™en rendre compte Ã  leurs cours refpeÃ¢ives. Cependant le peuple en gÃ©nÃ©ral gÃ©nÃ©ral nâ€™eft pas content, & on craint que dans lâ€™occafion il nâ€™cclate en murmures & peut- %re en tumultes fÃ©ditieux. Tous nos\", mean_ocr=0.5256414447269231, std_ocr=0.19060038635865742, bounding_boxes=[], item_id='9200396/BibliographicResource_3000118436230', metadata_xml_fname='test_data/metadata/http%3A%2F%2Fdata.theeuropeanlibrary.org%2FBibliographicResource%2F3000118436230.edm.xml', title='Journal historique et littÃ©raire', issued='1785-02-01', issued_parsed=datetime.datetime(1785, 2, 1, 0, 0), language=['fr'], item_iiif_url='https://iiif.europeana.eu/image/NGJNELURKNAPK5EL35D32X3AV36I7Z2X67NW4OGTN3EEO7L5N6NA/presentation_images/b171fd00-0222-11e6-a696-fa163e2dd531/node-3/image/BNL/Journal_historique_et_littÃ©raire/1785/02/01/00157/full/full/0/default.jpg', multi_language=False)"
  },
  {
    "objectID": "europena.html#dump-to-parquet",
    "href": "europena.html#dump-to-parquet",
    "title": "Europeana newspaper parsers",
    "section": "Dump to parquet",
    "text": "Dump to parquet\n\n\nprocess_batch\n\n process_batch (xml_batch:Iterable[Union[str,pathlib.Path]],\n                metadata_directory=None)\n\n\nds = process_batch(alto_xmls[:32], metadata_directory=\"test_data/metadata\")\nassert len(ds) == 32\nassert len(ds.column_names) == 13\nassert ds.column_names == [\n    \"fname\",\n    \"text\",\n    \"mean_ocr\",\n    \"std_ocr\",\n    \"bounding_boxes\",\n    \"item_id\",\n    \"metadata_xml_fname\",\n    \"title\",\n    \"issued\",\n    \"issued_parsed\",\n    \"language\",\n    \"item_iiif_url\",\n    \"multi_language\",\n]\n\n\nds\n\nDataset({\n    features: ['fname', 'text', 'mean_ocr', 'std_ocr', 'bounding_boxes', 'item_id', 'metadata_xml_fname', 'title', 'issued', 'issued_parsed', 'language', 'item_iiif_url', 'multi_language'],\n    num_rows: 32\n})\n\n\n\nds.features\n\n{'fname': Value(dtype='string', id=None),\n 'text': Value(dtype='string', id=None),\n 'mean_ocr': Value(dtype='float64', id=None),\n 'std_ocr': Value(dtype='float64', id=None),\n 'bounding_boxes': Sequence(feature=Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None), length=-1, id=None),\n 'item_id': Value(dtype='string', id=None),\n 'metadata_xml_fname': Value(dtype='string', id=None),\n 'title': Value(dtype='string', id=None),\n 'issued': Value(dtype='string', id=None),\n 'issued_parsed': Value(dtype='date64', id=None),\n 'language': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n 'item_iiif_url': Value(dtype='string', id=None),\n 'multi_language': Value(dtype='bool', id=None)}\n\n\n\n\n\nprocess\n\n process (xml_files:Iterable[Union[str,pathlib.Path]], batch_size:int=32,\n          metadata_directory:Union[pathlib.Path,str,NoneType]=None,\n          max_workers:Optional[int]=None)\n\n\ndatasets = process(alto_xmls[:10], metadata_directory=\"test_data/metadata\")\n\n\n\n\n\nfrom datasets import concatenate_datasets\n\n\ndataset = concatenate_datasets(datasets)\ndataset\n\nDataset({\n    features: ['fname', 'text', 'mean_ocr', 'std_ocr', 'bounding_boxes', 'item_id', 'metadata_xml_fname', 'title', 'issued', 'issued_parsed', 'language', 'item_iiif_url', 'multi_language'],\n    num_rows: 10\n})"
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "We donâ€™t want to leak our API key here so we need to filter this outâ€¦\n\n# data = keyfilter(lambda x: x !=\"apikey\",  data)\n# data['object']['aggregations']\n\n\n# page.item_id\n\n# r = httpx.get(f\"https://iiif.europeana.eu/presentation/{page.item_id}/manifest\")\n\n\n# page.text\n\n\n# data.keys()\n\n\n# def flatten(d, parent_key='', sep='_'):\n#     items = []\n#     for k, v in d.items():\n#         new_key = parent_key + sep + k if parent_key else k\n#         if isinstance(v, MutableMapping):\n#             items.extend(flatten(v, new_key, sep=sep).items())\n#         else:\n#             items.append((new_key, v))\n#     return dict(items)\n\n\n# flatten(data).keys()\n\n\n# flatten(data)\n\n\n# #| export \n# def simplify(obj: Any, key:Optional[str]=None):\n#     if type(obj) != dict:\n#         return obj\n#     r = {}\n#     for k, v in obj.items():\n#         if k == \"def\":\n#             r[key] = simplify(obj[k], k)\n#         else:\n#             r[f\"{key}-{k}\"] = simplify(obj[k], k)\n#     return r\n\n\n# @lru_cache(maxsize=512)\n# def metadata_for(id):\n#     r = f'https://api.europeana.eu/record/v2/{id}.json?wskey={API_KEY}'\n#     if not (r := requests.get(r)):\n#         return None\n#     try:\n#         data = r.json()['object']['proxies'][1]\n#         output = {}\n#         for k, v in data.items():\n#             item = simplify(v, k)\n#             if type(item) == dict:\n#                 for k2, v2 in item.items():\n#                     output[k2] = v2\n#             else:\n#                 output[k] = item\n#         return output\n#     except Exception as e:\n#         print(e)\n#         return None\n\n\n# from typing import Dict\n# from toolz import memoize\n\n\n# @dataclass(frozen=True)\n# class EuropeanaRecordAPI:\n#     API_KEY: str = field(repr=False)\n#     @lru_cache(maxsize=512)\n#     def __call__(self, id) -> Any:\n#         r = f'https://api.europeana.eu/record/v2/{id}.json?wskey={self.API_KEY}'\n#         if not (r := requests.get(r)):\n#             return None\n#         try:\n#             data = r.json()['object']['proxies'][1]\n#             output = {}\n#             for k, v in data.items():\n#                 item = simplify(v, k)\n#                 if type(item) == dict:\n#                     for k2, v2 in item.items():\n#                         output[k2] = v2\n#                 else:\n#                     output[k] = item\n#             return output\n#         except Exception as e:\n#             return None\n\n\n# api = EuropeanaRecordAPI(API_KEY)"
  }
]